"use strict";(self.webpackChunknewdocs=self.webpackChunknewdocs||[]).push([[2752],{2097:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>a,contentTitle:()=>i,default:()=>h,frontMatter:()=>d,metadata:()=>l,toc:()=>c});var n=r(4848),s=r(8453);const d={},i=void 0,l={id:"api/ext/transformers/model",title:"model",description:"superduperdb.ext.transformers.model",source:"@site/content/api/ext/transformers/model.md",sourceDirName:"api/ext/transformers",slug:"/api/ext/transformers/model",permalink:"/docs/api/ext/transformers/model",draft:!1,unlisted:!1,editUrl:"https://github.com/SuperDuperDB/superduperdb/blob/main/docs/hr/content/api/ext/transformers/model.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"utils",permalink:"/docs/api/ext/torch/utils"},next:{title:"training",permalink:"/docs/api/ext/transformers/training"}},a={},c=[{value:"<code>LLM</code>",id:"llm",level:2},{value:"<code>TextClassificationPipeline</code>",id:"textclassificationpipeline",level:2}];function o(e){const t={a:"a",code:"code",h2:"h2",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,s.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.p,{children:(0,n.jsx)(t.strong,{children:(0,n.jsx)(t.code,{children:"superduperdb.ext.transformers.model"})})}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.a,{href:"https://github.com/SuperDuperDB/superduperdb/blob/main/superduperdb/ext/transformers/model.py",children:"Source code"})}),"\n",(0,n.jsx)(t.h2,{id:"llm",children:(0,n.jsx)(t.code,{children:"LLM"})}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-python",children:"LLM(self,\n     db: dataclasses.InitVar[typing.Optional[ForwardRef('Datalayer')]] = None,\n     uuid: str = <factory>,\n     *,\n     trainer: 't.Optional[Trainer]' = None,\n     identifier: str = '',\n     artifacts: 'dc.InitVar[t.Optional[t.Dict]]' = None,\n     datatype: 'EncoderArg' = None,\n     output_schema: 't.Optional[Schema]' = None,\n     flatten: 'bool' = False,\n     model_update_kwargs: 't.Dict' = <factory>,\n     predict_kwargs: 't.Dict' = <factory>,\n     compute_kwargs: 't.Dict' = <factory>,\n     validation: 't.Optional[Validation]' = None,\n     metric_values: 't.Dict' = <factory>,\n     prompt: str = '{input}',\n     prompt_func: Optional[Callable] = None,\n     max_batch_size: Optional[int] = 4,\n     model_name_or_path: Optional[str] = None,\n     adapter_id: Union[str,\n     superduperdb.ext.transformers.training.Checkpoint,\n     NoneType] = None,\n     model_kwargs: Dict = <factory>,\n     tokenizer_kwargs: Dict = <factory>,\n     prompt_template: str = '{input}') -> None\n"})}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Parameter"}),(0,n.jsx)(t.th,{children:"Description"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"identifier"}),(0,n.jsx)(t.td,{children:"model identifier"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"db"}),(0,n.jsx)(t.td,{children:"Datalayer instance."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"uuid"}),(0,n.jsx)(t.td,{children:"UUID of the leaf."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"artifacts"}),(0,n.jsxs)(t.td,{children:["A dictionary of artifacts paths and ",(0,n.jsx)(t.code,{children:"DataType"})," objects"]})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"signature"}),(0,n.jsx)(t.td,{children:"Model signature."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"datatype"}),(0,n.jsx)(t.td,{children:"DataType instance."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"output_schema"}),(0,n.jsx)(t.td,{children:"Output schema (mapping of encoders)."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"flatten"}),(0,n.jsx)(t.td,{children:"Flatten the model outputs."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"model_update_kwargs"}),(0,n.jsx)(t.td,{children:"The kwargs to use for model update."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"predict_kwargs"}),(0,n.jsx)(t.td,{children:"Additional arguments to use at prediction time."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"compute_kwargs"}),(0,n.jsx)(t.td,{children:"Kwargs used for compute backend job submit. Example (Ray backend): compute_kwargs = dict(resources=...)."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"validation"}),(0,n.jsxs)(t.td,{children:["The validation ",(0,n.jsx)(t.code,{children:"Dataset"})," instances to use."]})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"metric_values"}),(0,n.jsx)(t.td,{children:"The metrics to evaluate on."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"prompt"}),(0,n.jsx)(t.td,{children:"The template to use for the prompt."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"prompt_func"}),(0,n.jsx)(t.td,{children:"prompt function, default is None"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"max_batch_size"}),(0,n.jsx)(t.td,{children:"The maximum batch size to use for batch generation."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"model_name_or_path"}),(0,n.jsx)(t.td,{children:"model name or path"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"adapter_id"}),(0,n.jsx)(t.td,{children:"adapter id, default is None Add a adapter to the base model for inference."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"model_kwargs"}),(0,n.jsxs)(t.td,{children:["model kwargs, all the kwargs will pass to ",(0,n.jsx)(t.code,{children:"transformers.AutoModelForCausalLM.from_pretrained"})]})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"tokenizer_kwargs"}),(0,n.jsxs)(t.td,{children:["tokenizer kwargs, all the kwargs will pass to ",(0,n.jsx)(t.code,{children:"transformers.AutoTokenizer.from_pretrained"})]})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"prompt_template"}),(0,n.jsxs)(t.td,{children:["prompt template, default is ",(0,n.jsx)(t.code,{children:'"{input}"'})]})]})]})]}),"\n",(0,n.jsxs)(t.p,{children:["LLM model based on ",(0,n.jsx)(t.code,{children:"transformers"})," library."]}),"\n",(0,n.jsxs)(t.p,{children:["All the ",(0,n.jsx)(t.code,{children:"model_kwargs"})," will pass to\n",(0,n.jsx)(t.code,{children:"transformers.AutoModelForCausalLM.from_pretrained"}),".\nAll the ",(0,n.jsx)(t.code,{children:"tokenize_kwargs"})," will pass to\n",(0,n.jsx)(t.code,{children:"transformers.AutoTokenizer.from_pretrained"}),".\nWhen ",(0,n.jsx)(t.code,{children:"model_name_or_path"}),", ",(0,n.jsx)(t.code,{children:"bits"}),", ",(0,n.jsx)(t.code,{children:"model_kwargs"}),", ",(0,n.jsx)(t.code,{children:"tokenizer_kwargs"})," are the same,\nwill share the same base model and tokenizer cache."]}),"\n",(0,n.jsx)(t.h2,{id:"textclassificationpipeline",children:(0,n.jsx)(t.code,{children:"TextClassificationPipeline"})}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-python",children:"TextClassificationPipeline(self,\n     identifier: str,\n     db: dataclasses.InitVar[typing.Optional[ForwardRef('Datalayer')]] = None,\n     uuid: str = <factory>,\n     *,\n     preferred_devices: 't.Sequence[str]' = ('cuda',\n     'mps',\n     'cpu'),\n     device: 't.Optional[str]' = None,\n     trainer: 't.Optional[Trainer]' = None,\n     artifacts: 'dc.InitVar[t.Optional[t.Dict]]' = None,\n     signature: Literal['*args',\n     '**kwargs',\n     '*args,\n    **kwargs',\n     'singleton'] = 'singleton',\n     datatype: 'EncoderArg' = None,\n     output_schema: 't.Optional[Schema]' = None,\n     flatten: 'bool' = False,\n     model_update_kwargs: 't.Dict' = <factory>,\n     predict_kwargs: 't.Dict' = <factory>,\n     compute_kwargs: 't.Dict' = <factory>,\n     validation: 't.Optional[Validation]' = None,\n     metric_values: 't.Dict' = <factory>,\n     tokenizer_name: Optional[str] = None,\n     tokenizer_cls: object = <class 'transformers.models.auto.tokenization_auto.AutoTokenizer'>,\n     tokenizer_kwargs: Dict = <factory>,\n     model_name: Optional[str] = None,\n     model_cls: object = <class 'transformers.models.auto.modeling_auto.AutoModelForSequenceClassification'>,\n     model_kwargs: Dict = <factory>,\n     pipeline: Optional[transformers.pipelines.base.Pipeline] = None,\n     task: str = 'text-classification') -> None\n"})}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Parameter"}),(0,n.jsx)(t.th,{children:"Description"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"identifier"}),(0,n.jsx)(t.td,{children:"Identifier of the leaf."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"db"}),(0,n.jsx)(t.td,{children:"Datalayer instance."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"uuid"}),(0,n.jsx)(t.td,{children:"UUID of the leaf."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"artifacts"}),(0,n.jsxs)(t.td,{children:["A dictionary of artifacts paths and ",(0,n.jsx)(t.code,{children:"DataType"})," objects"]})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"signature"}),(0,n.jsx)(t.td,{children:"Model signature."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"datatype"}),(0,n.jsx)(t.td,{children:"DataType instance."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"output_schema"}),(0,n.jsx)(t.td,{children:"Output schema (mapping of encoders)."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"flatten"}),(0,n.jsx)(t.td,{children:"Flatten the model outputs."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"model_update_kwargs"}),(0,n.jsx)(t.td,{children:"The kwargs to use for model update."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"predict_kwargs"}),(0,n.jsx)(t.td,{children:"Additional arguments to use at prediction time."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"compute_kwargs"}),(0,n.jsx)(t.td,{children:"Kwargs used for compute backend job submit. Example (Ray backend): compute_kwargs = dict(resources=...)."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"validation"}),(0,n.jsxs)(t.td,{children:["The validation ",(0,n.jsx)(t.code,{children:"Dataset"})," instances to use."]})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"metric_values"}),(0,n.jsx)(t.td,{children:"The metrics to evaluate on."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"tokenizer_name"}),(0,n.jsx)(t.td,{children:"tokenizer name"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"tokenizer_cls"}),(0,n.jsxs)(t.td,{children:["tokenizer class, e.g. ",(0,n.jsx)(t.code,{children:"transformers.AutoTokenizer"})]})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"tokenizer_kwargs"}),(0,n.jsxs)(t.td,{children:["tokenizer kwargs, will pass to ",(0,n.jsx)(t.code,{children:"tokenizer_cls"})]})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"model_name"}),(0,n.jsxs)(t.td,{children:["model name, will pass to ",(0,n.jsx)(t.code,{children:"model_cls"})]})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"model_cls"}),(0,n.jsxs)(t.td,{children:["model class, e.g. ",(0,n.jsx)(t.code,{children:"AutoModelForSequenceClassification"})]})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"model_kwargs"}),(0,n.jsxs)(t.td,{children:["model kwargs, will pass to ",(0,n.jsx)(t.code,{children:"model_cls"})]})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"pipeline"}),(0,n.jsx)(t.td,{children:"pipeline instance, default is None, will build when None"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"task"}),(0,n.jsx)(t.td,{children:"task of the pipeline"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"trainer"}),(0,n.jsxs)(t.td,{children:[(0,n.jsx)(t.code,{children:"TransformersTrainer"})," instance"]})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"preferred_devices"}),(0,n.jsx)(t.td,{children:"preferred devices"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:"device"}),(0,n.jsx)(t.td,{children:"device to use"})]})]})]}),"\n",(0,n.jsxs)(t.p,{children:["A wrapper for ",(0,n.jsx)(t.code,{children:"transformers.Pipeline"}),"."]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-python",children:"# Example:\n# -------\nmodel = TextClassificationPipeline(...)\n"})})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(o,{...e})}):o(e)}},8453:(e,t,r)=>{r.d(t,{R:()=>i,x:()=>l});var n=r(6540);const s={},d=n.createContext(s);function i(e){const t=n.useContext(d);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),n.createElement(d.Provider,{value:t},e.children)}}}]);