"use strict";(self.webpackChunknewdocs=self.webpackChunknewdocs||[]).push([[9381],{7368:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>p,frontMatter:()=>i,metadata:()=>a,toc:()=>l});var t=r(4848),s=r(8453);const i={},o="Stack",a={id:"apply_api/stack",title:"Stack",description:"- Wraps multiple potentially interdependent components",source:"@site/content/apply_api/stack.md",sourceDirName:"apply_api",slug:"/apply_api/stack",permalink:"/docs/apply_api/stack",draft:!1,unlisted:!1,editUrl:"https://github.com/SuperDuperDB/superduperdb/blob/main/docs/hr/content/apply_api/stack.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"VectorIndex",permalink:"/docs/apply_api/vector_index"},next:{title:"DataType",permalink:"/docs/apply_api/datatype"}},c={},l=[];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"stack",children:"Stack"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Wraps multiple potentially interdependent components"}),"\n",(0,t.jsx)(n.li,{children:'Allows developers to "apply" a range of functionality in a single declaration'}),"\n",(0,t.jsx)(n.li,{children:'Allows decision makers and admins to manage "groups" of AI functionality'}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:(0,t.jsx)(n.strong,{children:"Usage pattern"})})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from superduperdb import Stack\n\nstack = Stack(\n    'my-stack',\n    components=[\n        table_1,\n        model_1,\n        model_2,\n        listener_1,\n        vector_index_1,\n    ]\n)\n\ndb.apply(m)\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Here is an example in which vectors are prepared using a\nconvolutional neural network over images,\nand these vectors are used downstream in ",(0,t.jsx)(n.em,{children:(0,t.jsx)(n.strong,{children:"both"})}),"\nvector-search and in a transfer-learning task."]}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"Listener"})," instance, wraps the CNN ",(0,t.jsx)(n.code,{children:"'my-cnn-vectorizer'"}),",\nwhich contains the ",(0,t.jsx)(n.code,{children:"torch"})," layer and pre-processing/ post-processing."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"Stack"})," reuses this ",(0,t.jsx)(n.code,{children:"Listener"})," twice, once in the ",(0,t.jsx)(n.code,{children:"VectorIndex"}),",\nwhich may be used to find images, using images,\nand once with the support-vector-machine ",(0,t.jsx)(n.code,{children:"SVC()"}),", which ingests\nthe vectors calculated by the ",(0,t.jsx)(n.code,{children:"Listener"}),", and, is fitted\nbased on those vectors and the label set."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from sklearn.svm import SVC\nfrom my_models.vision import MyTorchModule, prepare_image\n\nfrom superduperdb.ext.numpy import array\nfrom superduperdb.ext.sklearn import Estimator, SklearnTrainer\nfrom superduperdb.ext.torch import TorchModel\nfrom superduperdb import Stack, VectorIndex, Listener\n\n\nmy_listener=Listener(\n    'my-listener',\n    model=TorchModel(\n        'my-cnn-vectorizer',\n        object=MyTorchModule(),\n        preprocess=prepare_image,\n        postprocess=lambda x: x.numpy(),\n        encoder=array(dtype='float', shape=(512,)),\n    )\n    key='img',\n    select=db['documents'].find({'_fold': 'train'}),\n)\n\ndb.apply(\n    Stack(\n        'my-stack',\n        [\n            my_listener,\n            VectorIndex(\n                'my-index',\n                indexing_listener=my_listener,\n            ),\n            Estimator(\n                'my-classifier',\n                object=SVC()\n                postprocess=lambda x: ['apples', 'pears'][x]\n                trainer=SklearnTrainer(\n                    'my-trainer',\n                    select=my_listener.select,\n                    key=(my_listener.outputs, labels),\n                )\n            )\n        ],\n    )\n)\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:(0,t.jsx)(n.strong,{children:"See also"})})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"../production/yaml_formalism.md",children:"YAML stack syntax"})}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>a});var t=r(6540);const s={},i=t.createContext(s);function o(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);