"use strict";(self.webpackChunknewdocs=self.webpackChunknewdocs||[]).push([[6662],{5099:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>t,metadata:()=>o,toc:()=>d});var s=n(4848),i=n(8453);const t={},a="Transformers",o={id:"ai_integrations/transformers",title:"Transformers",description:"Transformers is a popular AI framework, and we have incorporated native support for Transformers to provide essential Large Language Model (LLM) capabilities.",source:"@site/content/ai_integrations/transformers.md",sourceDirName:"ai_integrations",slug:"/ai_integrations/transformers",permalink:"/docs/ai_integrations/transformers",draft:!1,unlisted:!1,editUrl:"https://github.com/SuperDuperDB/superduperdb/blob/main/docs/hr/content/ai_integrations/transformers.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Scikit-learn",permalink:"/docs/ai_integrations/sklearn"},next:{title:"vLLM",permalink:"/docs/ai_integrations/vllm"}},l={},d=[{value:"<code>TextClassification</code>",id:"textclassification",level:3},{value:"<code>LLM</code>",id:"llm",level:3},{value:"Training",id:"training",level:2},{value:"LLM fine-tuning",id:"llm-fine-tuning",level:3},{value:"Supported Features",id:"supported-features",level:3}];function c(e){const r={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(r.h1,{id:"transformers",children:"Transformers"}),"\n",(0,s.jsxs)(r.p,{children:[(0,s.jsx)(r.a,{href:"https://huggingface.co/docs/transformers/index",children:"Transformers"})," is a popular AI framework, and we have incorporated native support for Transformers to provide essential Large Language Model (LLM) capabilities.\n",(0,s.jsx)(r.code,{children:"superduperdb"})," allows users to work with arbitrary ",(0,s.jsx)(r.code,{children:"transformers"})," pipelines, with custom input/ output data-types."]}),"\n",(0,s.jsxs)(r.table,{children:[(0,s.jsx)(r.thead,{children:(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.th,{children:"Class"}),(0,s.jsx)(r.th,{children:"Description"}),(0,s.jsx)(r.th,{children:"GitHub"}),(0,s.jsx)(r.th,{children:"API-docs"})]})}),(0,s.jsxs)(r.tbody,{children:[(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"superduperdb.ext.transformers.model.TextClassification"})}),(0,s.jsx)(r.td,{children:"A pipeline for classifying text."}),(0,s.jsx)(r.td,{children:(0,s.jsx)(r.a,{href:"https://github.com/SuperDuperDB/superduperdb/blob/main/superduperdb/transformers/model.py",children:"Code"})}),(0,s.jsx)(r.td,{children:(0,s.jsx)(r.a,{href:"/docs/api/ext/transformers/model#textclassificationpipeline",children:"Docs"})})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.code,{children:"superduperdb.ext.transformers.model.LLM"})}),(0,s.jsxs)(r.td,{children:["Work locally with the ",(0,s.jsx)(r.code,{children:"transformers"})," implementations of LLM."]}),(0,s.jsx)(r.td,{children:(0,s.jsx)(r.a,{href:"https://github.com/SuperDuperDB/superduperdb/blob/main/superduperdb/ext/transformers/model.py",children:"Code"})}),(0,s.jsx)(r.td,{children:(0,s.jsx)(r.a,{href:"/docs/api/ext/transformers/model#llm",children:"Docs"})})]})]})]}),"\n",(0,s.jsx)(r.h3,{id:"textclassification",children:(0,s.jsx)(r.code,{children:"TextClassification"})}),"\n",(0,s.jsxs)(r.p,{children:["One of the most commonly used pipelines in ",(0,s.jsx)(r.code,{children:"transformers"})," is the ",(0,s.jsx)(r.code,{children:"TextClassificationPipeline"}),".\nYou may apply and train these pipelines with ",(0,s.jsx)(r.code,{children:"superduperdb"}),".\nRead more in the ",(0,s.jsx)(r.a,{href:"/docs/api/ext/transformers/model#textclassificationpipeline",children:"API documentation"}),"."]}),"\n",(0,s.jsx)(r.h3,{id:"llm",children:(0,s.jsx)(r.code,{children:"LLM"})}),"\n",(0,s.jsx)(r.p,{children:"You can quickly utilize LLM capabilities using the following Python function:"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-python",children:'from superduperdb.ext.transformers import LLM\nllm = LLM(model_name_or_path="facebook/opt-350m")\nllm.predict("What are we having for dinner?")\n'})}),"\n",(0,s.jsx)(r.p,{children:"Or use a method similar to transformers\u2019 from_pretrained, just need to supplement the identifier parameter."}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-python",children:'from superduperdb.ext.transformers import LLM\nllm = LLM.from_pretrained(\n    "facebook/opt-350m", \n    load_in_8bit=True, \n    device_map="cuda", \n    identifier="llm",\n)\n'})}),"\n",(0,s.jsx)(r.p,{children:"The model can be configured with the following parameters:"}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsx)(r.li,{children:"adapter_id: Add an adapter to the base model for inference."}),"\n",(0,s.jsx)(r.li,{children:"model_kwargs: a dictionary; all the model_kwargs will be passed to transformers.AutoModelForCausalLM.from_pretrained. You can provide parameters such as trust_remote_code=True."}),"\n",(0,s.jsx)(r.li,{children:"tokenizer_kwargs: a dictionary; all the tokenizer_kwargs will be passed to transformers.AutoTokenizer.from_pretrained."}),"\n"]}),"\n",(0,s.jsx)(r.h2,{id:"training",children:"Training"}),"\n",(0,s.jsxs)(r.p,{children:["For a fully worked out training/ fine-tuning use-case refer to the ",(0,s.jsx)(r.a,{href:"/docs/use_cases/fine_tune_llm_on_database",children:"use-cases section"}),"."]}),"\n",(0,s.jsx)(r.h3,{id:"llm-fine-tuning",children:"LLM fine-tuning"}),"\n",(0,s.jsxs)(r.p,{children:["SuperDuperDB provides a convenient fine-tuning method based on the ",(0,s.jsx)(r.a,{href:"https://huggingface.co/docs/trl/index",children:"trl"})," framework to help you train data in the database."]}),"\n",(0,s.jsx)(r.h3,{id:"supported-features",children:"Supported Features"}),"\n",(0,s.jsxs)(r.p,{children:[(0,s.jsx)(r.strong,{children:"Training Methods"}),":"]}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsx)(r.li,{children:"Full fine-tuning"}),"\n",(0,s.jsx)(r.li,{children:"LoRA fine-tuning"}),"\n"]}),"\n",(0,s.jsxs)(r.p,{children:[(0,s.jsx)(r.strong,{children:"Parallel Training"}),":"]}),"\n",(0,s.jsxs)(r.p,{children:["Parallel training is supported using Ray, with data parallelism as the default strategy. You can also pass DeepSpeed parameters to configure parallelism through ",(0,s.jsx)(r.a,{href:"https://huggingface.co/docs/transformers/main_classes/deepspeed#zero",children:"DeepSpeed configuration"}),"."]}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsx)(r.li,{children:"Multi-GPUs fine-tuning"}),"\n",(0,s.jsx)(r.li,{children:"Multi-nodes fine-tuning"}),"\n"]}),"\n",(0,s.jsxs)(r.p,{children:[(0,s.jsx)(r.strong,{children:"Training on Ray"}),":"]}),"\n",(0,s.jsx)(r.p,{children:"We can use Ray to train models. When using Ray as the compute backend, tasks will automatically run in Ray and the program will no longer be blocked."})]})}function h(e={}){const{wrapper:r}={...(0,i.R)(),...e.components};return r?(0,s.jsx)(r,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,r,n)=>{n.d(r,{R:()=>a,x:()=>o});var s=n(6540);const i={},t=s.createContext(i);function a(e){const r=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(r):{...r,...e}}),[r,e])}function o(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),s.createElement(t.Provider,{value:r},e.children)}}}]);